---
title: Task 2
tags: Bug Fixing and Data Scraping
domain: Open Source
author: Authors - Umme Rooman & Manasa
---
<hr>

**<span style="color: #FF6363; font-size: 1rem;">Question 1</span>**

**Bug Hunt**

In this task, you'll be presented with a challenge code containing bugs and errors. Your objective is to identify the problems and provide appropriate solutions

_Instructions_
- Identify the issues in the provided challenge code.
- Explain the problem and provide a detailed solution.
- Submit your solutions for evaluation.

_Evaluation Criteria_
- Accuracy and correctness of bug identification and fixes..
- Clarity and completeness of problem descriptions and solutions.
- Proper application of Python syntax and conventions.
- Quality of explanations in the bug fixes.

This task is to test your bug fixing skills and also to familiarize yourself with GitHub Pull Requests(PRs) and GitHub
**Note : Some more buggy code will be added soon !!!** 
**For More Details regarding Submission**
- [<span style="color: #FFC0CB;">Github Link</span>](https://github.com/cognizance-amrita/OS-DOMAIN-TASK-2023)
<hr>

**<span style="color: #FF6363; font-size: 1rem;">Question 2</span>**

_Building a Web Crawler_

**To develop a crawler to automatically scrape data  from an online shop and get names, prices, ratings, and other relevant information and export to a json file.**

Web scraping is the process of automatically extracting data from websites. It involves using a program or script to access a website's HTML code, navigate through its structure, and gather specific information. This information can include text, images, prices, reviews, product details, and more.

In simpler terms, think of web scraping as a way to "scrape" or "pull" data from websites just like you would use a tool to scrape paint off a surface. Instead of paint, you're collecting useful data from web pages.

Web scraping can be done using various programming languages and libraries, with Python being a popular choice due to libraries like BeautifulSoup and Scrapy. 

However, it's important to note that web scraping might raise legal and ethical concerns, especially if done without proper permission or in violation of a website's terms of use.
**Scrapy**
Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing.

**Installation**
```lua
pip install scrapy
```
_References:_
- [<span style="color: #FFC0CB;">Web Crawling/Scraping Website </span>](https://books.toscrape.com) <p>For example, take this page where we have a lot of information like warning, results etc., and extract the data that we only care about like title, price and availability</p>
- [<span style="color: #FFC0CB;">Youtube Link 1</span>](https://www.youtube.com/watch?v=m_3gjHGxIJc&t=237s)
- [<span style="color: #FFC0CB;">Youtube Link 2</span>](https://www.youtube.com/watch?v=s4jtkzHhLzY&t=86s)
- [<span style="color: #FFC0CB;">Scrapy Docs</span>](https://docs.scrapy.org)

**Evaluation**
```lua
1. Functionality: Ensure that the script can crawl the selected website and extract the required information accurately.

2. Code quality: Clarity of the code, proper indentation, use of meaningful variable names, and comments explaining the logic (This will be helpful in the future when you are contributing to a Open Source organization).
```

**Submission Link (Deadline: 26th June,2023 @11:59PM)**


[<span style="color: #FFC0CB;">Forms Link</span>](https://forms.gle/guU539PnCj744mRy9) 

